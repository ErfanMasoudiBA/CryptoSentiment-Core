دانشگاه علم و صنعت ایران دانشکده مهندسی کامپیوتر
عنوان پروژه: طراحی و پیاده‌سازی سامانه هوشمند
تحلیل احساسات بازار رمزارز با رویکرد معماری ترکیبی (VADER و FinBERT)
استاد راهنما: جناب آقای دکتر خنجری
نگارش و پیاده‌سازی: عرفان (شماره دانشجویی: ۹۹۵۲۲۱۱۳)
زمستان ۱۴۰۴

صفحه دوم: چکیده (Abstract)
چکیده رشد روزافزون بازارهای مالی غیرمتمرکز (رمزارزها) و حجم عظیم اخبار منتشر شده در این حوزه، سرمایه‌گذاران را با پدیده‌ای به نام «بمباران اطلاعاتی» مواجه کرده است. تصمیم‌گیری در چنین بازار پرنوسانی نیازمند پردازش لحظه‌ای اخبار و درک دقیق احساسات (Sentiment) حاکم بر بازار است. مدل‌های سنتی تحلیل متن، به دلیل عدم شناخت اصطلاحات تخصصی مالی، غالباً در درک بافتار (Context) اخبار این حوزه دچار خطا می‌شوند. در این رساله، یک سامانه هوشمند، جامع و چندپلتفرمی (Cross-platform) جهت استخراج و تحلیل آنی اخبار بازار رمزارز طراحی و پیاده‌سازی شده است. معماری این سیستم شامل یک هسته پردازشی مبتنی بر پایتون (FastAPI)، پایگاه‌داده سبک، داشبورد تحت وب (Next.js) و اپلیکیشن موبایل (Flutter) می‌باشد. نوآوری اصلی این پژوهش، بهره‌گیری از یک موتور هوش مصنوعی ترکیبی (Hybrid AI Engine) است که مدل سریع و لغت‌نامه‌ای VADER را در کنار مدل پیشرفته و مبتنی بر ترنسفورمر FinBERT قرار می‌دهد. نتایج ارزیابی‌ها در سناریوهای پیچیده مالی نشان می‌دهد که مدل FinBERT با درک عمیق مفاهیمی نظیر «شوک عرضه» و «مدیریت ریسک»، به شکلی معنادار خطاهای تحلیلگران سنتی را کاهش داده و سیگنال‌های قابل‌اتکاتری جهت پشتیبانی از تصمیمات سرمایه‌گذاری ارائه می‌دهد.
کلمات کلیدی: تحلیل احساسات، بازار رمزارز، پردازش زبان طبیعی (NLP)، معماری مایکروسرویس، FinBERT، یادگیری عمیق.

فصل اول: کلیات پژوهش و طرح مسئله
۱-۱ مقدمه بازارهای مالی مدرن، به‌ویژه بازار رمزارزها، به شدت «خبرمحور» (News-driven) هستند. برخلاف بازارهای سنتی بورس که بر اساس صورت‌های مالی فصلی ارزش‌گذاری می‌شوند، دارایی‌های دیجیتال به صورت ۲۴ ساعته در حال نوسان بوده و کوچک‌ترین رویداد خبری، نظیر تغییرات قانون‌گذاری، هک شدن صرافی‌ها یا پذیرش تکنولوژی‌های جدید، می‌تواند در کسری از ثانیه روندهای قیمتی سهمگینی ایجاد کند. در چنین اکوسیستمی، اطلاعات به معنای واقعی کلمه معادل سرمایه است. با این حال، دسترسی به اطلاعات تنها نیمی از مسیر است؛ نیمه حیاتی‌تر، «توانایی پردازش و استخراج معنا» از این حجم انبوه داده‌های بدون ساختار (Unstructured Data) در کوتاه‌ترین زمان ممکن است.
۱-۲ بیان مسئله و ضرورت انجام تحقیق یک سرمایه‌گذار یا تحلیلگر روزانه با ده‌ها هزار تیتر خبری، توییت و گزارش مواجه است. تلاش برای خوانش و تحلیل دستی این حجم از داده، منجر به پدیده‌ای روان‌شناختی-مالی به نام «فلج تحلیلی» (Analysis Paralysis) می‌شود؛ وضعیتی که در آن فرد به دلیل دریافت اطلاعات متناقض و بیش از حد، توانایی تصمیم‌گیری منطقی را از دست داده و دچار رفتارهای هیجانی (FUD یا FOMO) می‌گردد. از سوی دیگر، استفاده از ابزارهای عمومی پردازش زبان طبیعی (مانند مدل‌های کلاسیک تحلیل احساسات) در متون مالی با چالش‌های جدی روبرو است. زبان بازارهای مالی، یک زبان تخصصی است که در آن کلماتی با بار معنایی منفی در زبان روزمره، ممکن است نشان‌گر یک اتفاق مثبت اقتصادی باشند. به عنوان مثال، در جمله «شرکت برای کاهش هزینه‌ها، نیروهای خود را تعدیل کرد»، کلمه «تعدیل/اخراج» از منظر یک مدل عمومی و لغت‌نامه‌ای، کاملاً منفی ارزیابی می‌شود، در حالی که از منظر علم اقتصاد و سهامداران، این اقدام منجر به افزایش حاشیه سود شده و خبری مثبت تلقی می‌گردد. لذا، مسئله اصلی این پژوهش، طراحی سیستمی است که نه‌تنها قادر به جمع‌آوری و یکپارچه‌سازی خودکار اخبار بازار باشد، بلکه بتواند با «درک منطق مالی»، متون را تحلیل کرده و جهت‌گیری بازار (صعودی، نزولی یا خنثی) را با درصد اطمینان بالا به کاربر نهایی (در قالب وب و موبایل) ارائه دهد.

فصل دوم: معماری سیستم و زیرساخت فناوری
۲-۱ معماری کلان سیستم (Macro Architecture) به منظور توسعه سامانه‌ای مقیاس‌پذیر، قابل نگهداری و مستقل از پلتفرم، در این پروژه از معماری مبتنی بر سرویس (Service-Oriented) و استاندارد RESTful API استفاده شده است. در این معماری، لایه منطق تجاری و پردازش هوش مصنوعی (Backend) کاملاً از لایه نمایش و تعامل با کاربر (Frontend) تفکیک شده است. این رویکردِ جداسازیِ دغدغه‌ها (Separation of Concerns) تضمین می‌کند که ارتقای مدل‌های یادگیری ماشین در سمت سرور، نیازمند هیچ‌گونه تغییر یا به‌روزرسانی در کدهای سمت کلاینت (اپلیکیشن موبایل یا وب‌سایت) نخواهد بود. چرخه حیات داده‌ها در این معماری شامل سه فاز اصلی است: جمع‌آوری (آفلاین و بلادرنگ)، پردازش معنایی (AI Engine) و ارائه گرافیکی (Data Visualization).
۲-۲ هسته پردازشی و توسعه واسط برنامه‌نویسی (Backend & API) قلب تپنده این سامانه با استفاده از زبان برنامه‌نویسی پایتون (Python) و چارچوب کاری قدرتمند FastAPI پیاده‌سازی شده است. انتخاب FastAPI به دلایل مهندسی متعددی صورت گرفته است؛ از جمله پشتیبانی ذاتی از برنامه‌نویسی ناهمگام (Asynchronous Programming) که برای مدیریت درخواست‌های همزمان به مدل‌های سنگین هوش مصنوعی حیاتی است، و همچنین سرعت اجرای بسیار بالا که با فریم‌ورک‌های کامپایل‌شده‌ای نظیر Node.js رقابت می‌کند. این هسته پردازشی وظیفه مسیریابی درخواست‌ها، فراخوانی مدل‌های VADER و FinBERT و مدیریت ارتباط با پایگاه‌داده را بر عهده دارد.

۲-۳ مدیریت داده‌ها و استراتژی ایزوله‌سازی (Data Management & Isolation) در لایه ذخیره‌سازی، از پایگاه‌داده رابطه‌ای SQLite به همراه نگاشتگر شیء-رابطه‌ای SQLAlchemy (ORM) استفاده شده است. استفاده از ORM انعطاف‌پذیری بالایی را فراهم می‌آورد تا در صورت نیاز به استقرار سامانه در محیط‌های عملیاتی وسیع‌تر (Production)، مهاجرت به پایگاه‌های داده قدرتمندتری نظیر PostgreSQL تنها با تغییر یک خط کد (Connection String) امکان‌پذیر باشد. یکی از اصول رعایت شده در طراحی این لایه، «ایزوله‌سازی داده‌ها» (Data Isolation) است. در این راستا، پایگاه‌داده به دو بخش کاملاً مجزا تقسیم شده است:
• بخش آرشیو (Historical Data): شامل بیش از ۳۰ هزار رکورد داده‌های استاتیک (برگرفته از مجموعه داده Kaggle) جهت تحلیل روندهای گذشته و ارزیابی اولیه مدل‌ها.
• بخش بلادرنگ (Live Data): یک جدول ایزوله (live_news) که منحصراً برای ذخیره اخبار لحظه‌ای واکشی شده از API سایت CryptoCompare تخصیص یافته است. این استراتژی از آلوده شدن داده‌های آموزشی با داده‌های عملیاتی جلوگیری کرده و یکپارچگی سیستم را تضمین می‌نماید.
۲-۴ لایه نمایش و رابط کاربری چندپلتفرمی (Cross-Platform Frontend) با توجه به نیاز سرمایه‌گذاران به رصد مداوم بازار در پلتفرم‌های مختلف، لایه کاربری این سامانه در دو بستر مجزا اما هماهنگ توسعه یافته است:
• داشبورد تحت وب (Web Dashboard): با بهره‌گیری از چارچوب Next.js (مبتنی بر React)، یک داشبورد تعاملی و واکنش‌گرا (Responsive) طراحی شده است که علاوه بر نمایش اخبار، محیطی به نام «آزمایشگاه هوش مصنوعی» (AI Playground) را جهت تست لحظه‌ای و مقایسه عملکرد مدل‌های تحلیلی در اختیار کاربر قرار می‌دهد.
• اپلیکیشن موبایل (Mobile App): جهت دسترسی‌پذیری حداکثری، یک نسخه بومی موبایل با استفاده از فریم‌ورک Flutter توسعه یافته است. این اپلیکیشن با مصرف مستقیم APIهای تولید شده در بک‌اند، تجربه‌ای یکپارچه و سریع را برای کاربر نهایی رقم می‌زند.

فصل سوم: هسته هوش مصنوعی؛ معماری و ارزیابی مدل‌ها
۳-۱ مقدمه و رویکرد انتخاب مدل در پیاده‌سازی موتور هوش مصنوعی (AI Engine) این سامانه، رویکرد «مهندسی انتخاب» (Engineering Selection) اتخاذ گردید. در فاز تحقیق و توسعه (R&D)، مدل‌های متعددی از جمله TextBlob (به عنوان مدل پایه پردازش زبان) و DistilBERT (به عنوان مدل عمومی شبکه عصبی) مورد ارزیابی قرار گرفتند. با این حال، نتایج نشان داد که مدل‌های عمومی فاقد «درک لغت‌نامه مالی» (Financial Lexicon) بوده و در مواجهه با اصطلاحات بازار رمزارز دچار خطای محاسباتی فاحش می‌شوند. از این رو، معماری نهایی بر پایه یک سیستم ترکیبی (Hybrid System) متشکل از دو مدل VADER و FinBERT بنا نهاده شد تا تعادلی میان «سرعت پردازش» و «دقت درک مفاهیم مالی» برقرار گردد.
۳-۲ مدل تحلیلگر VADER (Lexicon-based Analysis) مدل VADER (Valence Aware Dictionary and sEntiment Reasoner) یک رویکرد مبتنی بر لغت‌نامه و قواعد (Rule-based) است.
این مدل برای تحلیل متون در شبکه‌های اجتماعی بهینه‌سازی شده است و با سرعت پردازشی بسیار بالا (با استفاده از منابع CPU معمولی)، بار معنایی جملات را با محاسبه قطبیت کلمات (Polarity) استخراج می‌کند.
• مزایا: سرعت استنتاج (Inference) بسیار بالا، عدم نیاز به سخت‌افزار گرافیکی (GPU) و عملکرد مطلوب در تشخیص هیجانات عمومی (مانند FUD و FOMO).
• معایب: ناتوانی در درک بافتار (Context) جمله، وابستگی مطلق به کلمات منفرد، و شکست در تحلیل جملات دارای بار مالی پنهان.
۳-۳ مدل یادگیری عمیق FinBERT (Transformer-based Analysis) جهت پوشش ضعف‌های رویکرد لغت‌نامه‌ای، مدل FinBERT به عنوان تحلیلگر ارشد سامانه پیاده‌سازی گردید. FinBERT یک مدل زبانی بزرگ مبتنی بر معماری BERT گوگل است که توسط شرکت ProsusAI با استفاده از میلیون‌ها رکورد از متون، اخبار و گزارش‌های مالی بازآموزی (Fine-tune) شده است.
• مکانیسم عمل: این مدل با بهره‌گیری از لایه‌های توجه (Attention Mechanism)، کلمات را به صورت مجزا بررسی نمی‌کند، بلکه ارتباط معنایی هر کلمه را با کلمات قبل و بعد از آن در قالب بردارهای ریاضی (Tensors) می‌سنجد.
• مزایا: درک عمیق اصطلاحات تخصصی، توانایی استنتاج سود/زیان از متون پیچیده و دقت بسیار بالا در طبقه‌بندی احساسات بازار.
• معایب: پیچیدگی محاسباتی (Computational Complexity) بالا و نیاز به منابع سخت‌افزاری قدرتمندتر.
۳-۴ ارزیابی عملکرد و آزمون تضاد (Conflict Testing) به منظور اثبات برتری رویکرد مبتنی بر ترنسفورمر در دامنه مالی، یک سیستم ارزیابی خودکار (Batch Tester) توسعه یافت. در این آزمون، جملاتی با ساختار پیچیده اقتصادی به هر دو مدل تغذیه شد تا نقاط «تضاد خروجی» (Conflicts) شناسایی گردد. در ادامه، سه سناریوی کلیدی که تفاوت ماهوی دو مدل را به تصویر می‌کشند، تحلیل شده است:
• سناریوی اول: پارادوکس شوک عرضه (Supply Shock)
o متن آزمون: "The sudden supply shock caused the price to stabilize at a higher level."
o خروجی VADER: منفی (امتیاز: ۰.۳۸-)
o خروجی FinBERT: مثبت (امتیاز اطمینان: ۸۸٪)
o تحلیل علمی: مدل VADER با مشاهده کلمات "Sudden" و "Shock" دچار خطای ارزیابی احساسی شده و سیگنال منفی صادر کرد. در مقابل، FinBERT با درک اقتصاد توکنی (Tokenomics) تشخیص داد که «شوک عرضه» به معنای کمیابی دارایی بوده و تثبیت در قیمت‌های بالاتر (Stabilize at higher level) یک رویداد کاملاً مثبت برای سرمایه‌گذاران است.

• سناریوی دوم: کوری در برابر قانون (Regulatory Blindness)
o متن آزمون: "The strict regulations were finally lifted, opening doors for massive adoption."
o خروجی VADER: خنثی (امتیاز: ۰.۰)
o خروجی FinBERT: مثبت (امتیاز اطمینان: ۷۵٪)
o تحلیل علمی: در این سناریوی حقوقی، تقابل کلمه منفی "Strict" (سخت‌گیرانه) و کلمه مثبت "Lifted" (برداشته شد) باعث خنثی شدن امتیاز در مدل VADER گردید. اما FinBERT با تمرکز بر کلیدواژه‌های آینده‌نگرانه نظیر "Massive adoption" (پذیرش گسترده)، حذف قوانین بازدارنده را به درستی یک سیگنال صعودی تفسیر نمود.
• سناریوی سوم: مدیریت بحران و هک (Risk Management)
o متن آزمون: "The hack resulted in zero loss of user funds due to insurance coverage."
o خروجی VADER: منفی (امتیاز: ۰.۳۱-)
o خروجی FinBERT: خنثی (امتیاز اطمینان: ۷۸٪)
o تحلیل علمی: واژه "Hack" به صورت پیش‌فرض در مدل‌های سنتی یک هشدار قرمز است. با این حال، FinBERT با تحلیل انتهای جمله متوجه پوشش بیمه‌ای (Insurance coverage) و عدم زیان مالی (Zero loss) گردید. از آنجا که دارایی سیستم تغییر نکرده است، خروجی «خنثی» منطقی‌ترین و پایدارترین واکنش مالی به این خبر محسوب می‌شود که مانع از فروش هیجانی (Panic Sell) در سیستم‌های معاملاتی می‌گردد.
۳-۵ جمع‌بندی ارزیابی هوش مصنوعی نتایج این پژوهش ثابت می‌کند که اگرچه ابزارهای کلاسیک پردازش زبان طبیعی در سرعت پاسخ‌گویی پیشتاز هستند، اما در معماری سامانه‌های مالی (FinTech)، اتکا به کلماتِ مجزا می‌تواند منجر به تولید سیگنال‌های مخرب و زیان‌آور شود. ادغام مدل زبان تخصصی (FinBERT) در هسته سامانه، این پروژه را از یک خبرخوان ساده به یک دستیار تحلیلیِ باهوش ارتقا داده است.
فصل چهارم: پیاده‌سازی فاز عملیاتی و پردازش بلادرنگ (Real-Time Processing)
۴-۱ مقدمه فاز عملیاتی استفاده از مجموعه داده‌های ایستا (Static Datasets) نظیر آنچه در مسابقات Kaggle یافت می‌شود، برای آموزش و ارزیابی اولیه مدل‌های هوش مصنوعی ضروری است. اما ارزش واقعی یک سامانه فناوری مالی (FinTech)، در توانایی آن برای رصد، واکشی و تحلیل داده‌های زنده (Live Data) نهفته است. در این فصل، فرآیند تبدیل پروژه از یک محیط آزمایشگاهی به یک محصول عملیاتی با قابلیت مانیتورینگ بلادرنگ تشریح می‌گردد.
۴-۲ معماری خط لوله داده (Data Pipeline Architecture) جهت تزریق داده‌های زنده به سیستم، یک خط لوله داده‌ی خودکار (Automated Pipeline) در هسته بک‌اند (FastAPI) طراحی و پیاده‌سازی شد.
این خط لوله شامل سه مرحله اصلی است: ۱. واکشی داده (Data Ingestion): ماژول news_fetcher وظیفه برقراری ارتباط با وب‌سرویس‌های (API) معتبر مالی نظیر CryptoCompare را بر عهده دارد. این ماژول اخبار منتشر شده در لحظه را با فرمت JSON دریافت می‌کند. ۲. استنتاج آنی (Real-time Inference): اخبار خام بلافاصله به موتور هوش مصنوعی (کلاس CryptoAI) ارسال می‌شوند. در این مرحله، هر دو مدل VADER و FinBERT به صورت موازی متن خبر را تحلیل کرده و برچسب احساسات (Sentiment Label) و درصد اطمینان (Confidence Score) را محاسبه می‌کنند. ۳. ذخیره‌سازی و ایزوله‌سازی (Storage & Isolation): جهت حفظ یکپارچگی داده‌های تاریخی، رکورد جدید به جای ذخیره در جدول اصلی، در یک جدول کاملاً مجزا به نام live_news ذخیره می‌گردد. همچنین پیش از درج رکورد (Insert)، سیستم با بررسی هشِ آدرس اینترنتی (URL Hash) خبر، از عدم وجود داده‌های تکراری (Duplicate Detection) اطمینان حاصل می‌کند.
۴-۳ رابط کاربری مانیتورینگ زنده (Live Monitor Interface) برای نمایش اطلاعات پردازش شده، یک صفحه مجزا در داشبورد تحت وب (Next.js) و همچنین یک بخش اختصاصی در اپلیکیشن موبایل (Flutter) پیاده‌سازی شده است. کاربر با فشردن دکمه همگام‌سازی (Sync)، فرآیند واکشی و تحلیل بک‌اند را راه‌اندازی (Trigger) می‌کند. سیستم با نمایش یک نشانگر وضعیت (Loading State)، پس از اتمام تحلیل سنگین مدل FinBERT، خروجی نهایی را در قالب کارت‌های اطلاعاتی شامل تیتر خبر، منبع، زمان انتشار و نشانگر رنگی احساسات (سبز/قرمز/خاکستری) در اختیار سرمایه‌گذار قرار می‌دهد.
فصل پنجم: نتیجه‌گیری و توسعه‌های آتی
۵-۱ نتیجه‌گیری پژوهش و پیاده‌سازی حاضر، با هدف رفع معضل «اضافه‌بار اطلاعاتی» در بازارهای مالی غیرمتمرکز صورت گرفت. در این پروژه، یک سامانه جامع نرم‌افزاری با معماری میکروسرویس توسعه یافت که قادر است جریان اخبار خام را به سیگنال‌های قابل تصمیم‌گیری تبدیل نماید. بررسی‌های تحلیلی در این سامانه ثابت کرد که استفاده از مدل‌های زبانی عمومی یا لغت‌نامه‌ای (نظیر VADER) برای تحلیل متون تخصصی بورس و کریپتو، به دلیل عدم درک اقتصاد کلان و اصطلاحات بازار، می‌تواند منجر به تولید سیگنال‌های گمراه‌کننده شود. استقرار مدل مبتنی بر ترنسفورمر FinBERT به عنوان تحلیلگر ارشد سیستم، توانست خطای تشخیص در سناریوهای پیچیده‌ای نظیر «مدیریت بحران»، «قانون‌گذاری» و «تغییرات عرضه و تقاضا» را به طرز چشمگیری کاهش دهد و یک دستیار هوشمندِ قابل اتکا برای معامله‌گران فراهم آورد.
۵-۲ پیشنهادها و توسعه آینده (Future Works) معماری ماژولار این سامانه، بستر مناسبی را برای توسعه‌پذیری و ارتقاء در آینده فراهم آورده است. در همین راستا، توسعه‌های زیر برای فازهای بعدی پیشنهاد می‌گردد:
• معاملات الگوریتمی (Algorithmic Trading): اتصال خروجی‌های قطعیِ مدل FinBERT (با درصد اطمینان بالای ۹۰٪) به API صرافی‌های معتبر، جهت اجرای خودکار سفارشات خرید و فروش (Auto-trading) پیش از واکنش انسانی به اخبار.
• استقرار ابری (Cloud Deployment): کانتینرسازی (Containerization) کل پلتفرم با استفاده از Docker و استقرار آن بر روی سرورهای مجازی (VPS) جهت اجرای ۲۴ ساعته و تنظیم Cron Job برای واکشی خودکار اخبار بدون نیاز به دخالت کاربر.
• گسترش منابع داده (Data Enrichment): ادغام API شبکه‌های اجتماعی نظیر توییتر (X) برای تحلیل همزمان اخبار رسمی (Fundamental) و هیجانات توده‌ای (Social Sentiment) جهت تولید یک اندیکاتور ترکیبی قدرتمندتر.
